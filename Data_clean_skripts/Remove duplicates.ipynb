{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from 'C:\\\\Users\\\\katha\\\\OneDrive\\\\Dokumente\\\\02_UM\\\\2_semester\\\\03_ResearchProject\\\\Preprocessing\\\\data.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data\n",
    "import langid\n",
    "import importlib\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    return open(filename,encoding='utf-8').read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose name of datasets\n",
    "k = 'PIB'\n",
    "y = 'MKB'\n",
    "# rest will adjust by the k and y strings, so nothing needs to be done there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111135\n",
      "111135\n",
      "111135\n",
      "111135\n",
      "111135\n"
     ]
    }
   ],
   "source": [
    "en_sent_k=[]\n",
    "for i in range(1,6):\n",
    "    file=readfile(f'../Corpus/00_Single_Clean_unsplitted_Corpus/{k}_endata_unique.txt')\n",
    "\n",
    "    print(len(file))\n",
    "    for i in range(len(file)):\n",
    "        en_sent_k.append(file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111135\n",
      "111135\n",
      "111135\n",
      "111135\n",
      "111135\n"
     ]
    }
   ],
   "source": [
    "ta_sent_k=[]\n",
    "for i in range(1,6):\n",
    "    file=readfile(f'../Corpus/00_Single_Clean_unsplitted_Corpus/{k}_tadata_unique.txt')\n",
    "\n",
    "    print(len(file))\n",
    "    for i in range(len(file)):\n",
    "        ta_sent_k.append(file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5724\n",
      "5724\n",
      "5724\n",
      "5724\n",
      "5724\n"
     ]
    }
   ],
   "source": [
    "en_sent_y=[]\n",
    "for i in range(1,6):\n",
    "    file=readfile(f'../Corpus/00_Single_Clean_unsplitted_Corpus/{y}_endata_unique.txt')\n",
    "\n",
    "    print(len(file))\n",
    "    for i in range(len(file)):\n",
    "        en_sent_y.append(file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5724\n",
      "5724\n",
      "5724\n",
      "5724\n",
      "5724\n"
     ]
    }
   ],
   "source": [
    "ta_sent_y=[]\n",
    "for i in range(1,6):\n",
    "    file=readfile(f'../Corpus/00_Single_Clean_unsplitted_Corpus/{y}_tadata_unique.txt')\n",
    "\n",
    "    print(len(file))\n",
    "    for i in range(len(file)):\n",
    "        ta_sent_y.append(file[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the datasets to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sets to the mix variable. \n",
    "#structure: english *|* tamil\n",
    "mix=[]\n",
    "for i,j in zip(en_sent_k,ta_sent_k):\n",
    "    mix.append(i+\"*|*\"+j)\n",
    "    \n",
    "for i,j in zip(en_sent_y,ta_sent_y):\n",
    "    mix.append(i+\"*|*\"+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix=list(set(mix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116859"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split again for further checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data=[]\n",
    "ta_data=[]\n",
    "for i in mix:\n",
    "    i=i.split(\"*|*\")\n",
    "    en_data.append(i[0])\n",
    "    ta_data.append(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing same source with different translation and same translation with different source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Counter(en_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove=[]\n",
    "for i,j in a.items():\n",
    "    if j>1:\n",
    "        remove.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data2=[]\n",
    "ta_data2=[]\n",
    "for i in range(len(en_data)):\n",
    "    if en_data[i] not in remove:\n",
    "        en_data2.append(en_data[i])\n",
    "        ta_data2.append(ta_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116859"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Counter(ta_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove2=[]\n",
    "for i,j in b.items():\n",
    "    if j>1:\n",
    "        remove2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data3=[]\n",
    "ta_data3=[]\n",
    "for i in range(len(ta_data2)):\n",
    "    if ta_data2[i] not in remove2:\n",
    "        en_data3.append(en_data2[i])\n",
    "        ta_data3.append(ta_data2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116859"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total amount of sentences in the dataset after cleaning\n",
    "len(en_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save new Corpus of y and k in 04_Joint_Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_sentences(sentences1,sentences2,filename1,filename2):\n",
    "    file1 = open(filename1, 'w',encoding='utf-8')\n",
    "    file2 = open(filename2, 'w',encoding='utf-8')\n",
    "    for i,j in zip(sentences1,sentences2):\n",
    "        file1.write(\"%s\\n\" % i)\n",
    "        file2.write(\"%s\\n\" % j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean_sentences(en_data3,ta_data3,f'../Corpus/04_Joint_Corpus/{k}_{y}_endata.txt',f'../Corpus/04_Joint_Corpus/{k}_{y}_tadata.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
